{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prediction Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from prediction_util import *\n",
    "from training_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WNT1(NM_005430.3) DNA sequence for example\n",
    "seq = '''GCGGTGCCGCCCGCCGTGGCCGCCTCAGCCCACCAGCCGGGACCGCGAGCCATGCTGTCCGCCGCCCGCC\n",
    "CCCAGGGTTGTTAAAGCCAGACTGCGAACTCTCGCCACTGCCGCCACCGCCGCGTCCCGTCCCACCGTCG\n",
    "CGGGCAACAACCAAAGTCGCCGCAACTGCAGCACAGAGCGGGCAAAGCCAGGCAGGCCATGGGGCTCTGG\n",
    "GCGCTGTTGCCTGGCTGGGTTTCTGCTACGCTGCTGCTGGCGCTGGCCGCTCTGCCCGCAGCCCTGGCTG\n",
    "CCAACAGCAGTGGCCGATGGTGGGGTATTGTGAACGTAGCCTCCTCCACGAACCTGCTTACAGACTCCAA\n",
    "GAGTCTGCAACTGGTACTCGAGCCCAGTCTGCAGCTGTTGAGCCGCAAACAGCGGCGTCTGATACGCCAA\n",
    "AATCCGGGGATCCTGCACAGCGTGAGTGGGGGGCTGCAGAGTGCCGTGCGCGAGTGCAAGTGGCAGTTCC\n",
    "GGAATCGCCGCTGGAACTGTCCCACTGCTCCAGGGCCCCACCTCTTCGGCAAGATCGTCAACCGAGGCTG\n",
    "TCGAGAAACGGCGTTTATCTTCGCTATCACCTCCGCCGGGGTCACCCATTCGGTGGCGCGCTCCTGCTCA\n",
    "GAAGGTTCCATCGAATCCTGCACGTGTGACTACCGGCGGCGCGGCCCCGGGGGCCCCGACTGGCACTGGG\n",
    "GGGGCTGCAGCGACAACATTGACTTCGGCCGCCTCTTCGGCCGGGAGTTCGTGGACTCCGGGGAGAAGGG\n",
    "GCGGGACCTGCGCTTCCTCATGAACCTTCACAACAACGAGGCAGGCCGTACGACCGTATTCTCCGAGATG\n",
    "CGCCAGGAGTGCAAGTGCCACGGGATGTCCGGCTCATGCACGGTGCGCACGTGCTGGATGCGGCTGCCCA\n",
    "CGCTGCGCGCCGTGGGCGATGTGCTGCGCGACCGCTTCGACGGCGCCTCGCGCGTCCTGTACGGCAACCG\n",
    "CGGCAGCAACCGCGCTTCGCGGGCGGAGCTGCTGCGCCTGGAGCCGGAAGACCCGGCCCACAAACCGCCC\n",
    "TCCCCCCACGACCTCGTCTACTTCGAGAAATCGCCCAACTTCTGCACGTACAGCGGACGCCTGGGCACAG\n",
    "CAGGCACGGCAGGGCGCGCCTGTAACAGCTCGTCGCCCGCGCTGGACGGCTGCGAGCTGCTCTGCTGCGG\n",
    "CAGGGGCCACCGCACGCGCACGCAGCGCGTCACCGAGCGCTGCAACTGCACCTTCCACTGGTGCTGCCAC\n",
    "GTCAGCTGCCGCAACTGCACGCACACGCGCGTACTGCACGAGTGTCTGTGAGGCGCTGCGCGGACTCGCC\n",
    "CCCAGGAACGCTCTCCTCGAGCCCTCCCCCAAACAGACTCGCTAGCACTCAAGACCCGGTTATTCGCCCA\n",
    "CCCGAGTACCTCCAGTCACACTCCCCGCGGTTCATACGCATCCCATCTCTCCCACTTCCTCCTACCTGGG\n",
    "GACTCCTCAAACCACTTGCCTGGGGCGGCATGAACCCTCTTGCCATCCTGATGGACCTGCCCCGGACCTA\n",
    "CCTCCCTCCCTCTCCGCGGGAGACCCCTTGTTGCACTGCCCCCTGCTTGGCCAGGAGGTGAGAGAAGGAT\n",
    "GGGTCCCCTCCGCCATGGGGTCGGCTCCTGATGGTGTCATTCTGCCTGCTCCATCGCGCCAGCGACCTCT\n",
    "CTGCCTCTCTTCTTCCCCTTTGTCCTGCGTTTTCTCCGGGTCCTCCTAAGTCCCTTCCTATTCTCCTGCC\n",
    "ATGGGTGCAGACCCTGAACCCACACCTGGGCATCAGGGCCTTTCTCCTCCCCACCTGTAGCTGAAGCAGG\n",
    "AGGTTACAGGGCAAAAGGGCAGCTGTGATGATGTGGAAATGAGGTTGGGGGAACCAGCAGAAATGCCCCC\n",
    "ATTCTCCCAGTCTCTGTCGTGGAGCCATTGAACAGCTGTGAGCCATGCCTCCCTGGGCCACCTCCTACCC\n",
    "CTTCCTGTCCTGCCTCCTCATCAGTGTGTAAATAATTTGCACTGAAACGTGGATACAGAGCCACGAGTTT\n",
    "GGATGTTGTAAATAAAACTATTTATTGTGCTGGGTCCCAGCCTGGTTTGCAAAGACCACCTCCAACCCAA\n",
    "CCCAATCCCTCTCCACTCTTCTCTCCTTTCTCCCTGCAGCCTTTTCTGGTCCCTCTTCTCTCCTCAGTTT\n",
    "CTCAAAGATGCGTTTGCCTCCTGGAATCAGTATTTCCTTCCACTGTAGCTATTAGCGGCTCCTCGCCCCC\n",
    "ACCAGTGTAGCATCTTCCTCTGCAGAATAAAATCTCTATTTTTA'''\n",
    "enzyme = 'esp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing sencondary structure features.\n",
      "N-None,N2-1\n",
      "N-None,N2-1\n",
      "Constructing nucleotide features.\n",
      "N-None,N2-1\n",
      "N-None,N2-1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Strand</th>\n",
       "      <th>Cut_Pos</th>\n",
       "      <th>PAM</th>\n",
       "      <th>gRNA_Seq</th>\n",
       "      <th>Efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "      <td>17</td>\n",
       "      <td>CGG</td>\n",
       "      <td>ACGTGTGACTACCGGCGGCG</td>\n",
       "      <td>0.28913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Strand  Cut_Pos  PAM              gRNA_Seq  Efficiency\n",
       "0      0      +       17  CGG  ACGTGTGACTACCGGCGGCG     0.28913"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effciency_predict('ACGTGTGACTACCGGCGGCGCGG','esp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing sencondary structure features.\n",
      "N-None,N2-441\n",
      "N-None,N2-441\n",
      "Constructing nucleotide features.\n",
      "N-None,N2-441\n",
      "N-None,N2-441\n"
     ]
    }
   ],
   "source": [
    "result = effciency_predict(seq.replace(os.linesep, ''), enzyme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Strand</th>\n",
       "      <th>Cut_Pos</th>\n",
       "      <th>PAM</th>\n",
       "      <th>gRNA_Seq</th>\n",
       "      <th>Efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>292</td>\n",
       "      <td>-</td>\n",
       "      <td>856</td>\n",
       "      <td>GGG</td>\n",
       "      <td>TGGGATGCGTATGAACCGCG</td>\n",
       "      <td>0.73154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>290</td>\n",
       "      <td>-</td>\n",
       "      <td>854</td>\n",
       "      <td>CGG</td>\n",
       "      <td>GATGGGATGCGTATGAACCG</td>\n",
       "      <td>0.68387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>242</td>\n",
       "      <td>-</td>\n",
       "      <td>575</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GGAGGACCCGGAGAAAACGC</td>\n",
       "      <td>0.67997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>311</td>\n",
       "      <td>-</td>\n",
       "      <td>950</td>\n",
       "      <td>GGG</td>\n",
       "      <td>CTCGAGGAGAGCGTTCCTGG</td>\n",
       "      <td>0.67690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>176</td>\n",
       "      <td>-</td>\n",
       "      <td>69</td>\n",
       "      <td>TGG</td>\n",
       "      <td>GGAGCCGCTAATAGCTACAG</td>\n",
       "      <td>0.67012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>187</td>\n",
       "      <td>-</td>\n",
       "      <td>166</td>\n",
       "      <td>TGG</td>\n",
       "      <td>AGGGAGAAAGGAGAGAAGAG</td>\n",
       "      <td>0.66913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>247</td>\n",
       "      <td>-</td>\n",
       "      <td>603</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GGGGAAGAAGAGAGGCAGAG</td>\n",
       "      <td>0.66690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>221</td>\n",
       "      <td>-</td>\n",
       "      <td>393</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GACAGAGACTGGGAGAATGG</td>\n",
       "      <td>0.66322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>304</td>\n",
       "      <td>-</td>\n",
       "      <td>923</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GTGCTAGCGAGTCTGTTTGG</td>\n",
       "      <td>0.65476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>103</td>\n",
       "      <td>+</td>\n",
       "      <td>1128</td>\n",
       "      <td>GGG</td>\n",
       "      <td>TGGGCACAGCAGGCACGGCA</td>\n",
       "      <td>0.64987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>349</td>\n",
       "      <td>-</td>\n",
       "      <td>1421</td>\n",
       "      <td>TGG</td>\n",
       "      <td>TGCATGAGCCGGACATCCCG</td>\n",
       "      <td>0.64846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>225</td>\n",
       "      <td>-</td>\n",
       "      <td>479</td>\n",
       "      <td>GGG</td>\n",
       "      <td>CTCCTGCTTCAGCTACAGGT</td>\n",
       "      <td>0.64492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>423</td>\n",
       "      <td>-</td>\n",
       "      <td>2209</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GTCTGGCTTTAACAACCCTG</td>\n",
       "      <td>0.64413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>+</td>\n",
       "      <td>551</td>\n",
       "      <td>AGG</td>\n",
       "      <td>TTCGGCAAGATCGTCAACCG</td>\n",
       "      <td>0.64072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>237</td>\n",
       "      <td>-</td>\n",
       "      <td>546</td>\n",
       "      <td>AGG</td>\n",
       "      <td>CCCATGGCAGGAGAATAGGA</td>\n",
       "      <td>0.63614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>181</td>\n",
       "      <td>-</td>\n",
       "      <td>127</td>\n",
       "      <td>AGG</td>\n",
       "      <td>TGAGAAACTGAGGAGAGAAG</td>\n",
       "      <td>0.62194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>+</td>\n",
       "      <td>697</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGGCCCCGACTGGCACTGGG</td>\n",
       "      <td>0.61947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>188</td>\n",
       "      <td>-</td>\n",
       "      <td>171</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GAAAGGAGAGAAGAGTGGAG</td>\n",
       "      <td>0.60351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>421</td>\n",
       "      <td>-</td>\n",
       "      <td>2207</td>\n",
       "      <td>TGG</td>\n",
       "      <td>CAGTCTGGCTTTAACAACCC</td>\n",
       "      <td>0.60268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>106</td>\n",
       "      <td>+</td>\n",
       "      <td>1184</td>\n",
       "      <td>CGG</td>\n",
       "      <td>GGCTGCGAGCTGCTCTGCTG</td>\n",
       "      <td>0.60202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>118</td>\n",
       "      <td>+</td>\n",
       "      <td>1465</td>\n",
       "      <td>GGG</td>\n",
       "      <td>CTCCCACTTCCTCCTACCTG</td>\n",
       "      <td>0.60045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115</td>\n",
       "      <td>+</td>\n",
       "      <td>1424</td>\n",
       "      <td>CGG</td>\n",
       "      <td>ACCTCCAGTCACACTCCCCG</td>\n",
       "      <td>0.59730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>345</td>\n",
       "      <td>-</td>\n",
       "      <td>1359</td>\n",
       "      <td>CGG</td>\n",
       "      <td>GTCGCGCAGCACATCGCCCA</td>\n",
       "      <td>0.58892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>132</td>\n",
       "      <td>+</td>\n",
       "      <td>1607</td>\n",
       "      <td>GGG</td>\n",
       "      <td>CCAGGAGGTGAGAGAAGGAT</td>\n",
       "      <td>0.58863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>+</td>\n",
       "      <td>446</td>\n",
       "      <td>GGG</td>\n",
       "      <td>ATCCTGCACAGCGTGAGTGG</td>\n",
       "      <td>0.58802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>396</td>\n",
       "      <td>-</td>\n",
       "      <td>1956</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GTCTGTAAGCAGGTTCGTGG</td>\n",
       "      <td>0.58644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>264</td>\n",
       "      <td>-</td>\n",
       "      <td>715</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GCAGGGGGCAGTGCAACAAG</td>\n",
       "      <td>0.58443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>260</td>\n",
       "      <td>-</td>\n",
       "      <td>699</td>\n",
       "      <td>GGG</td>\n",
       "      <td>CTCACCTCCTGGCCAAGCAG</td>\n",
       "      <td>0.57722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>329</td>\n",
       "      <td>-</td>\n",
       "      <td>1226</td>\n",
       "      <td>GGG</td>\n",
       "      <td>CGAAGTAGACGAGGTCGTGG</td>\n",
       "      <td>0.57161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>171</td>\n",
       "      <td>-</td>\n",
       "      <td>40</td>\n",
       "      <td>TGG</td>\n",
       "      <td>AGAGGAAGATGCTACACTGG</td>\n",
       "      <td>0.56234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>122</td>\n",
       "      <td>+</td>\n",
       "      <td>1492</td>\n",
       "      <td>CGG</td>\n",
       "      <td>CTCAAACCACTTGCCTGGGG</td>\n",
       "      <td>0.09007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>351</td>\n",
       "      <td>-</td>\n",
       "      <td>1446</td>\n",
       "      <td>CGG</td>\n",
       "      <td>CTTGCACTCCTGGCGCATCT</td>\n",
       "      <td>0.08765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>413</td>\n",
       "      <td>-</td>\n",
       "      <td>2152</td>\n",
       "      <td>CGG</td>\n",
       "      <td>TGTTGCCCGCGACGGTGGGA</td>\n",
       "      <td>0.08654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>+</td>\n",
       "      <td>223</td>\n",
       "      <td>GGG</td>\n",
       "      <td>CTGGGCGCTGTTGCCTGGCT</td>\n",
       "      <td>0.08498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>167</td>\n",
       "      <td>+</td>\n",
       "      <td>2188</td>\n",
       "      <td>TGG</td>\n",
       "      <td>TCAAAGATGCGTTTGCCTCC</td>\n",
       "      <td>0.08429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>293</td>\n",
       "      <td>-</td>\n",
       "      <td>867</td>\n",
       "      <td>TGG</td>\n",
       "      <td>TGAACCGCGGGGAGTGTGAC</td>\n",
       "      <td>0.08390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>201</td>\n",
       "      <td>-</td>\n",
       "      <td>303</td>\n",
       "      <td>AGG</td>\n",
       "      <td>AAATTATTTACACACTGATG</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>216</td>\n",
       "      <td>-</td>\n",
       "      <td>382</td>\n",
       "      <td>TGG</td>\n",
       "      <td>AATGGCTCCACGACAGAGAC</td>\n",
       "      <td>0.08337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>163</td>\n",
       "      <td>+</td>\n",
       "      <td>2057</td>\n",
       "      <td>TGG</td>\n",
       "      <td>AATAAAACTATTTATTGTGC</td>\n",
       "      <td>0.08277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>+</td>\n",
       "      <td>271</td>\n",
       "      <td>TGG</td>\n",
       "      <td>GGCCGCTCTGCCCGCAGCCC</td>\n",
       "      <td>0.08127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>-</td>\n",
       "      <td>213</td>\n",
       "      <td>GGG</td>\n",
       "      <td>TGGTCTTTGCAAACCAGGCT</td>\n",
       "      <td>0.08125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>233</td>\n",
       "      <td>-</td>\n",
       "      <td>517</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GATGCCCAGGTGTGGGTTCA</td>\n",
       "      <td>0.08122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>400</td>\n",
       "      <td>-</td>\n",
       "      <td>2006</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GGCCACTGCTGTTGGCAGCC</td>\n",
       "      <td>0.08095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>+</td>\n",
       "      <td>687</td>\n",
       "      <td>TGG</td>\n",
       "      <td>GCGGCCCCGGGGGCCCCGAC</td>\n",
       "      <td>0.08050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>342</td>\n",
       "      <td>-</td>\n",
       "      <td>1313</td>\n",
       "      <td>AGG</td>\n",
       "      <td>TGCTGCCGCGGTTGCCGTAC</td>\n",
       "      <td>0.08020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>+</td>\n",
       "      <td>250</td>\n",
       "      <td>TGG</td>\n",
       "      <td>TGCTACGCTGCTGCTGGCGC</td>\n",
       "      <td>0.07936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>381</td>\n",
       "      <td>-</td>\n",
       "      <td>1759</td>\n",
       "      <td>TGG</td>\n",
       "      <td>TTGCCGAAGAGGTGGGGCCC</td>\n",
       "      <td>0.07813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>+</td>\n",
       "      <td>734</td>\n",
       "      <td>CGG</td>\n",
       "      <td>ATTGACTTCGGCCGCCTCTT</td>\n",
       "      <td>0.07631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>385</td>\n",
       "      <td>-</td>\n",
       "      <td>1790</td>\n",
       "      <td>CGG</td>\n",
       "      <td>GACAGTTCCAGCGGCGATTC</td>\n",
       "      <td>0.07492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>107</td>\n",
       "      <td>+</td>\n",
       "      <td>1188</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GCGAGCTGCTCTGCTGCGGC</td>\n",
       "      <td>0.07404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>232</td>\n",
       "      <td>-</td>\n",
       "      <td>516</td>\n",
       "      <td>AGG</td>\n",
       "      <td>TGATGCCCAGGTGTGGGTTC</td>\n",
       "      <td>0.07324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>186</td>\n",
       "      <td>-</td>\n",
       "      <td>154</td>\n",
       "      <td>AGG</td>\n",
       "      <td>AGAAAAGGCTGCAGGGAGAA</td>\n",
       "      <td>0.07246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>414</td>\n",
       "      <td>-</td>\n",
       "      <td>2153</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GTTGCCCGCGACGGTGGGAC</td>\n",
       "      <td>0.07096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>223</td>\n",
       "      <td>-</td>\n",
       "      <td>475</td>\n",
       "      <td>AGG</td>\n",
       "      <td>TAACCTCCTGCTTCAGCTAC</td>\n",
       "      <td>0.06838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>317</td>\n",
       "      <td>-</td>\n",
       "      <td>1079</td>\n",
       "      <td>CGG</td>\n",
       "      <td>TGACGCGCTGCGTGCGCGTG</td>\n",
       "      <td>0.06663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "      <td>+</td>\n",
       "      <td>1714</td>\n",
       "      <td>GGG</td>\n",
       "      <td>CTTTGTCCTGCGTTTTCTCC</td>\n",
       "      <td>0.06236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>165</td>\n",
       "      <td>+</td>\n",
       "      <td>2069</td>\n",
       "      <td>TGG</td>\n",
       "      <td>TATTGTGCTGGGTCCCAGCC</td>\n",
       "      <td>0.06098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>166</td>\n",
       "      <td>+</td>\n",
       "      <td>2143</td>\n",
       "      <td>TGG</td>\n",
       "      <td>TTTCTCCCTGCAGCCTTTTC</td>\n",
       "      <td>0.05567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>409</td>\n",
       "      <td>-</td>\n",
       "      <td>2128</td>\n",
       "      <td>TGG</td>\n",
       "      <td>TGCTGCAGTTGCGGCGACTT</td>\n",
       "      <td>0.05504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>164</td>\n",
       "      <td>+</td>\n",
       "      <td>2058</td>\n",
       "      <td>GGG</td>\n",
       "      <td>ATAAAACTATTTATTGTGCT</td>\n",
       "      <td>0.04642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index Strand  Cut_Pos  PAM              gRNA_Seq  Efficiency\n",
       "292    292      -      856  GGG  TGGGATGCGTATGAACCGCG     0.73154\n",
       "290    290      -      854  CGG  GATGGGATGCGTATGAACCG     0.68387\n",
       "242    242      -      575  AGG  GGAGGACCCGGAGAAAACGC     0.67997\n",
       "311    311      -      950  GGG  CTCGAGGAGAGCGTTCCTGG     0.67690\n",
       "176    176      -       69  TGG  GGAGCCGCTAATAGCTACAG     0.67012\n",
       "187    187      -      166  TGG  AGGGAGAAAGGAGAGAAGAG     0.66913\n",
       "247    247      -      603  AGG  GGGGAAGAAGAGAGGCAGAG     0.66690\n",
       "221    221      -      393  GGG  GACAGAGACTGGGAGAATGG     0.66322\n",
       "304    304      -      923  GGG  GTGCTAGCGAGTCTGTTTGG     0.65476\n",
       "103    103      +     1128  GGG  TGGGCACAGCAGGCACGGCA     0.64987\n",
       "349    349      -     1421  TGG  TGCATGAGCCGGACATCCCG     0.64846\n",
       "225    225      -      479  GGG  CTCCTGCTTCAGCTACAGGT     0.64492\n",
       "423    423      -     2209  GGG  GTCTGGCTTTAACAACCCTG     0.64413\n",
       "42      42      +      551  AGG  TTCGGCAAGATCGTCAACCG     0.64072\n",
       "237    237      -      546  AGG  CCCATGGCAGGAGAATAGGA     0.63614\n",
       "181    181      -      127  AGG  TGAGAAACTGAGGAGAGAAG     0.62194\n",
       "62      62      +      697  GGG  GGGCCCCGACTGGCACTGGG     0.61947\n",
       "188    188      -      171  AGG  GAAAGGAGAGAAGAGTGGAG     0.60351\n",
       "421    421      -     2207  TGG  CAGTCTGGCTTTAACAACCC     0.60268\n",
       "106    106      +     1184  CGG  GGCTGCGAGCTGCTCTGCTG     0.60202\n",
       "118    118      +     1465  GGG  CTCCCACTTCCTCCTACCTG     0.60045\n",
       "115    115      +     1424  CGG  ACCTCCAGTCACACTCCCCG     0.59730\n",
       "345    345      -     1359  CGG  GTCGCGCAGCACATCGCCCA     0.58892\n",
       "132    132      +     1607  GGG  CCAGGAGGTGAGAGAAGGAT     0.58863\n",
       "34      34      +      446  GGG  ATCCTGCACAGCGTGAGTGG     0.58802\n",
       "396    396      -     1956  AGG  GTCTGTAAGCAGGTTCGTGG     0.58644\n",
       "264    264      -      715  GGG  GCAGGGGGCAGTGCAACAAG     0.58443\n",
       "260    260      -      699  GGG  CTCACCTCCTGGCCAAGCAG     0.57722\n",
       "329    329      -     1226  GGG  CGAAGTAGACGAGGTCGTGG     0.57161\n",
       "171    171      -       40  TGG  AGAGGAAGATGCTACACTGG     0.56234\n",
       "..     ...    ...      ...  ...                   ...         ...\n",
       "122    122      +     1492  CGG  CTCAAACCACTTGCCTGGGG     0.09007\n",
       "351    351      -     1446  CGG  CTTGCACTCCTGGCGCATCT     0.08765\n",
       "413    413      -     2152  CGG  TGTTGCCCGCGACGGTGGGA     0.08654\n",
       "17      17      +      223  GGG  CTGGGCGCTGTTGCCTGGCT     0.08498\n",
       "167    167      +     2188  TGG  TCAAAGATGCGTTTGCCTCC     0.08429\n",
       "293    293      -      867  TGG  TGAACCGCGGGGAGTGTGAC     0.08390\n",
       "201    201      -      303  AGG  AAATTATTTACACACTGATG     0.08368\n",
       "216    216      -      382  TGG  AATGGCTCCACGACAGAGAC     0.08337\n",
       "163    163      +     2057  TGG  AATAAAACTATTTATTGTGC     0.08277\n",
       "20      20      +      271  TGG  GGCCGCTCTGCCCGCAGCCC     0.08127\n",
       "199    199      -      213  GGG  TGGTCTTTGCAAACCAGGCT     0.08125\n",
       "233    233      -      517  GGG  GATGCCCAGGTGTGGGTTCA     0.08122\n",
       "400    400      -     2006  AGG  GGCCACTGCTGTTGGCAGCC     0.08095\n",
       "57      57      +      687  TGG  GCGGCCCCGGGGGCCCCGAC     0.08050\n",
       "342    342      -     1313  AGG  TGCTGCCGCGGTTGCCGTAC     0.08020\n",
       "19      19      +      250  TGG  TGCTACGCTGCTGCTGGCGC     0.07936\n",
       "381    381      -     1759  TGG  TTGCCGAAGAGGTGGGGCCC     0.07813\n",
       "65      65      +      734  CGG  ATTGACTTCGGCCGCCTCTT     0.07631\n",
       "385    385      -     1790  CGG  GACAGTTCCAGCGGCGATTC     0.07492\n",
       "107    107      +     1188  AGG  GCGAGCTGCTCTGCTGCGGC     0.07404\n",
       "232    232      -      516  AGG  TGATGCCCAGGTGTGGGTTC     0.07324\n",
       "186    186      -      154  AGG  AGAAAAGGCTGCAGGGAGAA     0.07246\n",
       "414    414      -     2153  GGG  GTTGCCCGCGACGGTGGGAC     0.07096\n",
       "223    223      -      475  AGG  TAACCTCCTGCTTCAGCTAC     0.06838\n",
       "317    317      -     1079  CGG  TGACGCGCTGCGTGCGCGTG     0.06663\n",
       "139    139      +     1714  GGG  CTTTGTCCTGCGTTTTCTCC     0.06236\n",
       "165    165      +     2069  TGG  TATTGTGCTGGGTCCCAGCC     0.06098\n",
       "166    166      +     2143  TGG  TTTCTCCCTGCAGCCTTTTC     0.05567\n",
       "409    409      -     2128  TGG  TGCTGCAGTTGCGGCGACTT     0.05504\n",
       "164    164      +     2058  GGG  ATAAAACTATTTATTGTGCT     0.04642\n",
       "\n",
       "[441 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Prediction metrics demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.realpath( './' )\n",
    "esp_model_file_path = os.path.join( dir_path, 'models/esp_rnn_model.hd5' )\n",
    "hf_model_file_path = os.path.join( dir_path, 'models/hf_rnn_model.hd5' )\n",
    "model_esp = load_model( esp_model_file_path)\n",
    "model_hf = load_model( hf_model_file_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MES:0.007770613899385625', 'Spearman:0.8861134817457584')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## esp model prediction metrics\n",
    "get_metrics(model_esp,'esp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MES:0.008558173115465145', 'Spearman:0.8805147791848338')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## hf model prediction metrics\n",
    "get_metrics(model_hf,'hf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Model training demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### eSpCas9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44841 samples, validate on 4983 samples\n",
      "Epoch 1/45\n",
      " - 27s - loss: 0.2279 - val_loss: 0.0346\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03457, storing weights.\n",
      "Epoch 2/45\n",
      " - 26s - loss: 0.0414 - val_loss: 0.0339\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03457 to 0.03393, storing weights.\n",
      "Epoch 3/45\n",
      " - 28s - loss: 0.0376 - val_loss: 0.0327\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03393 to 0.03268, storing weights.\n",
      "Epoch 4/45\n",
      " - 30s - loss: 0.0349 - val_loss: 0.0306\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03268 to 0.03064, storing weights.\n",
      "Epoch 5/45\n",
      " - 26s - loss: 0.0318 - val_loss: 0.0282\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.03064 to 0.02818, storing weights.\n",
      "Epoch 6/45\n",
      " - 25s - loss: 0.0277 - val_loss: 0.0236\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02818 to 0.02361, storing weights.\n",
      "Epoch 7/45\n",
      " - 26s - loss: 0.0249 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02361 to 0.02124, storing weights.\n",
      "Epoch 8/45\n",
      " - 26s - loss: 0.0231 - val_loss: 0.0207\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02124 to 0.02067, storing weights.\n",
      "Epoch 9/45\n",
      " - 26s - loss: 0.0219 - val_loss: 0.0199\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.02067 to 0.01987, storing weights.\n",
      "Epoch 10/45\n",
      " - 25s - loss: 0.0208 - val_loss: 0.0181\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01987 to 0.01810, storing weights.\n",
      "Epoch 11/45\n",
      " - 26s - loss: 0.0196 - val_loss: 0.0172\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01810 to 0.01721, storing weights.\n",
      "Epoch 12/45\n",
      " - 25s - loss: 0.0187 - val_loss: 0.0167\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01721 to 0.01671, storing weights.\n",
      "Epoch 13/45\n",
      " - 26s - loss: 0.0179 - val_loss: 0.0158\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01671 to 0.01583, storing weights.\n",
      "Epoch 14/45\n",
      " - 29s - loss: 0.0173 - val_loss: 0.0155\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01583 to 0.01549, storing weights.\n",
      "Epoch 15/45\n",
      " - 25s - loss: 0.0169 - val_loss: 0.0148\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01549 to 0.01478, storing weights.\n",
      "Epoch 16/45\n",
      " - 27s - loss: 0.0162 - val_loss: 0.0139\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01478 to 0.01391, storing weights.\n",
      "Epoch 17/45\n",
      " - 27s - loss: 0.0156 - val_loss: 0.0133\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01391 to 0.01330, storing weights.\n",
      "Epoch 18/45\n",
      " - 25s - loss: 0.0151 - val_loss: 0.0128\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01330 to 0.01283, storing weights.\n",
      "Epoch 19/45\n",
      " - 25s - loss: 0.0145 - val_loss: 0.0126\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01283 to 0.01260, storing weights.\n",
      "Epoch 20/45\n",
      " - 26s - loss: 0.0141 - val_loss: 0.0122\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01260 to 0.01218, storing weights.\n",
      "Epoch 21/45\n",
      " - 33s - loss: 0.0137 - val_loss: 0.0117\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01218 to 0.01168, storing weights.\n",
      "Epoch 22/45\n",
      " - 31s - loss: 0.0133 - val_loss: 0.0114\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01168 to 0.01141, storing weights.\n",
      "Epoch 23/45\n",
      " - 26s - loss: 0.0129 - val_loss: 0.0115\n",
      "\n",
      "Epoch 00023: val_loss did not improve.\n",
      "Epoch 24/45\n",
      " - 26s - loss: 0.0126 - val_loss: 0.0110\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.01141 to 0.01102, storing weights.\n",
      "Epoch 25/45\n",
      " - 25s - loss: 0.0123 - val_loss: 0.0109\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01102 to 0.01086, storing weights.\n",
      "Epoch 26/45\n",
      " - 24s - loss: 0.0121 - val_loss: 0.0106\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01086 to 0.01059, storing weights.\n",
      "Epoch 27/45\n",
      " - 24s - loss: 0.0118 - val_loss: 0.0104\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.01059 to 0.01040, storing weights.\n",
      "Epoch 28/45\n",
      " - 24s - loss: 0.0116 - val_loss: 0.0103\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.01040 to 0.01026, storing weights.\n",
      "Epoch 29/45\n",
      " - 24s - loss: 0.0115 - val_loss: 0.0102\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.01026 to 0.01015, storing weights.\n",
      "Epoch 30/45\n",
      " - 24s - loss: 0.0112 - val_loss: 0.0100\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.01015 to 0.01004, storing weights.\n",
      "Epoch 31/45\n",
      " - 24s - loss: 0.0110 - val_loss: 0.0099\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.01004 to 0.00994, storing weights.\n",
      "Epoch 32/45\n",
      " - 24s - loss: 0.0108 - val_loss: 0.0099\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00994 to 0.00987, storing weights.\n",
      "Epoch 33/45\n",
      " - 24s - loss: 0.0106 - val_loss: 0.0098\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00987 to 0.00976, storing weights.\n",
      "Epoch 34/45\n",
      " - 24s - loss: 0.0105 - val_loss: 0.0097\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00976 to 0.00971, storing weights.\n",
      "Epoch 35/45\n",
      " - 24s - loss: 0.0103 - val_loss: 0.0096\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00971 to 0.00960, storing weights.\n",
      "Epoch 36/45\n",
      " - 24s - loss: 0.0102 - val_loss: 0.0096\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00960 to 0.00955, storing weights.\n",
      "Epoch 37/45\n",
      " - 24s - loss: 0.0100 - val_loss: 0.0095\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00955 to 0.00954, storing weights.\n",
      "Epoch 38/45\n",
      " - 24s - loss: 0.0100 - val_loss: 0.0095\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00954 to 0.00949, storing weights.\n",
      "Epoch 39/45\n",
      " - 25s - loss: 0.0097 - val_loss: 0.0096\n",
      "\n",
      "Epoch 00039: val_loss did not improve.\n",
      "Epoch 40/45\n",
      " - 24s - loss: 0.0096 - val_loss: 0.0094\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00949 to 0.00944, storing weights.\n",
      "Epoch 41/45\n",
      " - 25s - loss: 0.0095 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00944 to 0.00933, storing weights.\n",
      "Epoch 42/45\n",
      " - 24s - loss: 0.0095 - val_loss: 0.0094\n",
      "\n",
      "Epoch 00042: val_loss did not improve.\n",
      "Epoch 43/45\n",
      " - 24s - loss: 0.0093 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00043: val_loss did not improve.\n",
      "Epoch 44/45\n",
      " - 24s - loss: 0.0092 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00933 to 0.00931, storing weights.\n",
      "Epoch 45/45\n",
      " - 24s - loss: 0.0091 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00045: val_loss did not improve.\n",
      "Using epoch 00044 with val_loss: 0.00931.\n"
     ]
    }
   ],
   "source": [
    "param = {'model_type':'esp',\n",
    "        'em_drop':0.2,\n",
    "        'rnn_drop':0.5,\n",
    "        'rnn_rec_drop':0.4,\n",
    "        'fc_drop':0.4,\n",
    "        'batch_size':80,\n",
    "        'epochs':45,\n",
    "        'em_dim':44,\n",
    "        'rnn_units':80,\n",
    "        'fc_num_hidden_layers':3,\n",
    "        'fc_num_units':300,\n",
    "        'fc_activation':'3',\n",
    "        'optimizer':'6'}\n",
    "\n",
    "trained_esp_model = lstm_model(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MES:0.0074479781967959095', 'Spearman:0.8921754376074847')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(trained_esp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cas9-HF1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43518 samples, validate on 4836 samples\n",
      "Epoch 1/45\n",
      " - 24s - loss: 0.2527 - val_loss: 0.0410\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04102, storing weights.\n",
      "Epoch 2/45\n",
      " - 22s - loss: 0.0476 - val_loss: 0.0380\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04102 to 0.03800, storing weights.\n",
      "Epoch 3/45\n",
      " - 22s - loss: 0.0428 - val_loss: 0.0355\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03800 to 0.03550, storing weights.\n",
      "Epoch 4/45\n",
      " - 22s - loss: 0.0395 - val_loss: 0.0331\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03550 to 0.03306, storing weights.\n",
      "Epoch 5/45\n",
      " - 23s - loss: 0.0355 - val_loss: 0.0293\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.03306 to 0.02933, storing weights.\n",
      "Epoch 6/45\n",
      " - 22s - loss: 0.0318 - val_loss: 0.0268\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02933 to 0.02677, storing weights.\n",
      "Epoch 7/45\n",
      " - 1413s - loss: 0.0294 - val_loss: 0.0246\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02677 to 0.02462, storing weights.\n",
      "Epoch 8/45\n",
      " - 1637s - loss: 0.0267 - val_loss: 0.0220\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02462 to 0.02202, storing weights.\n",
      "Epoch 9/45\n",
      " - 88s - loss: 0.0246 - val_loss: 0.0202\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.02202 to 0.02023, storing weights.\n",
      "Epoch 10/45\n",
      " - 88s - loss: 0.0230 - val_loss: 0.0189\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02023 to 0.01890, storing weights.\n",
      "Epoch 11/45\n",
      " - 87s - loss: 0.0212 - val_loss: 0.0173\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01890 to 0.01733, storing weights.\n",
      "Epoch 12/45\n",
      " - 89s - loss: 0.0199 - val_loss: 0.0162\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01733 to 0.01617, storing weights.\n",
      "Epoch 13/45\n",
      " - 87s - loss: 0.0186 - val_loss: 0.0147\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01617 to 0.01465, storing weights.\n",
      "Epoch 14/45\n",
      " - 88s - loss: 0.0178 - val_loss: 0.0144\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01465 to 0.01435, storing weights.\n",
      "Epoch 15/45\n",
      " - 88s - loss: 0.0171 - val_loss: 0.0139\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01435 to 0.01391, storing weights.\n",
      "Epoch 16/45\n",
      " - 87s - loss: 0.0165 - val_loss: 0.0137\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01391 to 0.01367, storing weights.\n",
      "Epoch 17/45\n",
      " - 87s - loss: 0.0160 - val_loss: 0.0131\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01367 to 0.01305, storing weights.\n",
      "Epoch 18/45\n",
      " - 88s - loss: 0.0154 - val_loss: 0.0126\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01305 to 0.01261, storing weights.\n",
      "Epoch 19/45\n",
      " - 88s - loss: 0.0150 - val_loss: 0.0124\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01261 to 0.01244, storing weights.\n",
      "Epoch 20/45\n",
      " - 87s - loss: 0.0148 - val_loss: 0.0121\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01244 to 0.01208, storing weights.\n",
      "Epoch 21/45\n",
      " - 87s - loss: 0.0145 - val_loss: 0.0120\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01208 to 0.01200, storing weights.\n",
      "Epoch 22/45\n",
      " - 89s - loss: 0.0140 - val_loss: 0.0120\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01200 to 0.01197, storing weights.\n",
      "Epoch 23/45\n",
      " - 87s - loss: 0.0138 - val_loss: 0.0116\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.01197 to 0.01158, storing weights.\n",
      "Epoch 24/45\n",
      " - 87s - loss: 0.0135 - val_loss: 0.0115\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.01158 to 0.01145, storing weights.\n",
      "Epoch 25/45\n",
      " - 87s - loss: 0.0132 - val_loss: 0.0113\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01145 to 0.01126, storing weights.\n",
      "Epoch 26/45\n",
      " - 1070s - loss: 0.0129 - val_loss: 0.0111\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01126 to 0.01113, storing weights.\n",
      "Epoch 27/45\n",
      " - 706s - loss: 0.0128 - val_loss: 0.0111\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.01113 to 0.01108, storing weights.\n",
      "Epoch 28/45\n",
      " - 23s - loss: 0.0125 - val_loss: 0.0111\n",
      "\n",
      "Epoch 00028: val_loss did not improve.\n",
      "Epoch 29/45\n",
      " - 23s - loss: 0.0124 - val_loss: 0.0109\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.01108 to 0.01092, storing weights.\n",
      "Epoch 30/45\n",
      " - 24s - loss: 0.0122 - val_loss: 0.0108\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.01092 to 0.01082, storing weights.\n",
      "Epoch 31/45\n",
      " - 26s - loss: 0.0120 - val_loss: 0.0107\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.01082 to 0.01073, storing weights.\n",
      "Epoch 32/45\n",
      " - 23s - loss: 0.0119 - val_loss: 0.0107\n",
      "\n",
      "Epoch 00032: val_loss did not improve.\n",
      "Epoch 33/45\n",
      " - 23s - loss: 0.0117 - val_loss: 0.0107\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.01073 to 0.01065, storing weights.\n",
      "Epoch 34/45\n",
      " - 26s - loss: 0.0115 - val_loss: 0.0105\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.01065 to 0.01052, storing weights.\n",
      "Epoch 35/45\n",
      " - 25s - loss: 0.0114 - val_loss: 0.0105\n",
      "\n",
      "Epoch 00035: val_loss did not improve.\n",
      "Epoch 36/45\n",
      " - 23s - loss: 0.0113 - val_loss: 0.0105\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.01052 to 0.01046, storing weights.\n",
      "Epoch 37/45\n",
      " - 24s - loss: 0.0111 - val_loss: 0.0104\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.01046 to 0.01040, storing weights.\n",
      "Epoch 38/45\n",
      " - 25s - loss: 0.0110 - val_loss: 0.0104\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.01040 to 0.01037, storing weights.\n",
      "Epoch 39/45\n",
      " - 26s - loss: 0.0109 - val_loss: 0.0103\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.01037 to 0.01027, storing weights.\n",
      "Epoch 40/45\n",
      " - 28s - loss: 0.0108 - val_loss: 0.0103\n",
      "\n",
      "Epoch 00040: val_loss did not improve.\n",
      "Epoch 41/45\n",
      " - 25s - loss: 0.0107 - val_loss: 0.0102\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.01027 to 0.01023, storing weights.\n",
      "Epoch 42/45\n",
      " - 24s - loss: 0.0105 - val_loss: 0.0102\n",
      "\n",
      "Epoch 00042: val_loss did not improve.\n",
      "Epoch 43/45\n",
      " - 23s - loss: 0.0104 - val_loss: 0.0101\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.01023 to 0.01011, storing weights.\n",
      "Epoch 44/45\n",
      " - 23s - loss: 0.0103 - val_loss: 0.0101\n",
      "\n",
      "Epoch 00044: val_loss did not improve.\n",
      "Epoch 45/45\n",
      " - 25s - loss: 0.0103 - val_loss: 0.0102\n",
      "\n",
      "Epoch 00045: val_loss did not improve.\n",
      "Using epoch 00043 with val_loss: 0.01011.\n"
     ]
    }
   ],
   "source": [
    "param = {'model_type':'hf',\n",
    "    'em_drop': 0.2, \n",
    "     'rnn_drop': 0.5, \n",
    "     'rnn_rec_drop': 0.4, \n",
    "     'fc_drop': 0.5, \n",
    "     'batch_size': 80, \n",
    "     'epochs': 45, \n",
    "     'em_dim': 48, \n",
    "     'rnn_units': 80, \n",
    "     'fc_num_hidden_layers': 2, \n",
    "     'fc_num_units': 300, \n",
    "     'fc_activation': 3, \n",
    "     'optimizer': 6}\n",
    "\n",
    "trained_hf_model = lstm_model(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MES:0.008565540312178864', 'Spearman:0.8803655561707214')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(trained_hf_model,'hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3(crispr)",
   "language": "python",
   "name": "crispr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
